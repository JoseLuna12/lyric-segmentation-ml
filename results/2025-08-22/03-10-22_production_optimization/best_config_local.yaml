anti_collapse:
  weighted_sampling: true
calibration:
  enabled: true
  methods:
  - temperature
  - platt
data:
  test_file: data/test.jsonl
  train_file: data/train.jsonl
  val_file: data/val.jsonl
embeddings:
  contextual:
    enabled: true
    high_sim_threshold: 0.7357313328864075
    mode: complete
    model: all-MiniLM-L6-v2
    normalize: false
    similarity_metric: dot
  word2vec:
    enabled: true
    high_sim_threshold: 0.7790157926645429
    mode: summary
    model: word2vec-google-news-300
    normalize: false
    similarity_metric: dot
emergency_monitoring:
  enabled: true
  max_chorus_rate: 0.8588235803166872
  max_conf_over_95_ratio: 0.060648837087697076
  max_confidence_threshold: 0.9517057428962626
  min_chorus_rate: 0.13293940631218104
  val_f1_collapse_threshold: 0.1
  val_overconf_threshold: 0.96
experiment_name: best_hyperopt_config_20250822_031147
features:
  head_ssm:
    dimension: 12
    enabled: false
    words: 4
  line_syllable_ssm:
    dimension: 12
    enabled: false
    normalize: false
    normalize_method: minmax
    ratio_threshold: 0.08433152938830307
    similarity_method: cosine
  phonetic_ssm:
    dimension: 12
    enabled: true
    high_sim_threshold: 0.3435498950023245
    mode: alliteration
    normalize: false
    normalize_method: zscore
    similarity_method: edit_distance
  pos_ssm:
    dimension: 12
    enabled: false
    high_sim_threshold: 0.31456208727107976
    similarity_method: combined
    tagset: penn
  string_ssm:
    case_sensitive: true
    dimension: 12
    enabled: true
    remove_punctuation: true
    similarity_method: jaccard
    similarity_threshold: 0.0559463723544822
  syllable_pattern_ssm:
    cosine_weight: 0.25419072992624187
    dimension: 12
    enabled: true
    levenshtein_weight: 0.7132091648269921
    normalize: true
    normalize_method: minmax
    similarity_method: cosine
  tail_ssm:
    dimension: 12
    enabled: true
    words: 4
loss:
  boundary_weight: 1.2263661865535764
  conf_penalty_lambda: 0.017456186076982336
  conf_threshold: 0.9103844238435979
  entropy_lambda: 0.02735446053170428
  label_smoothing: 0.25650743367009
  segment_consistency_lambda: 0.03556555486849983
  type: boundary_aware
model:
  attention_dim: 512
  attention_dropout: 0.18433211114721396
  attention_enabled: true
  attention_heads: 4
  attention_type: boundary_aware
  boundary_temperature: 2.0
  dropout: 0.14075303986004872
  hidden_dim: 512
  layer_dropout: 0.0
  max_seq_length: 1000
  num_classes: 2
  num_layers: 1
  positional_encoding: true
  window_size: 7
optimization_info:
  best_boundary_f1: 0.0
  calibration_always_enabled: true
  compatibility_enforced: true
  config_mode: LOCAL (no external files)
  n_trials: 5
  optimization_date: '2025-08-22T03:11:47.588364'
  optimized_with_optuna: true
  static_embedding_models: true
  study_name: production_optimization
training:
  batch_size: 32
  cosine_t0: 10
  cosine_t_max: 30
  cosine_t_mult: 2
  gradient_clip_norm: 1.196412431862656
  learning_rate: 0.00017255719032870922
  lr_factor: 0.5
  lr_patience: 10
  max_epochs: 30
  min_delta: 0.000551849131697058
  min_lr: 1.0e-06
  patience: 5
  scheduler: cosine_restarts
  step_gamma: 0.5
  step_size: 30
  warmup_epochs: 5
  weight_decay: 0.00019248579427110114
validation:
  strategy: line_f1
