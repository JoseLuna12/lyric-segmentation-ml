# Enhanced BiLSTM Configuration with LEGACY CROSS-ENTROPY LOSS
# Based on successful all_features_active_training.yaml (0.85 F1 performance)
# Using proven legacy loss function with conservative but effective settings

# =============================================================================
# LOSS CONFIGURATION - LEGACY CROSS-ENTROPY
# =============================================================================
loss:
  type: "cross_entropy"
  
  # Core parameters
  num_classes: 2
  ignore_index: -100
  
  # Proven safety mechanisms
  label_smoothing: 0.12         # Matches anti_collapse setting from original
  # class_weights: Automatically calculated from dataset statistics (inverse frequency, capped at 2.0 ratio)
  entropy_lambda: 0.08          # Matches anti_collapse entropy_lambda from original
  
  # Legacy loss characteristics:
  # - Stable and reliable token-level accuracy
  # - Proven anti-collapse mechanisms
  # - Conservative approach for comparison baseline

# =============================================================================
# DATA CONFIGURATION
# =============================================================================
data:
  train_file: "data/train.jsonl"
  val_file: "data/val.jsonl"
  test_file: "data/test.jsonl"

# =============================================================================
# MODEL ARCHITECTURE - PROVEN 2-LAYER SETUP
# =============================================================================
model:
  hidden_dim: 256
  num_layers: 2        # 2-layer architecture that achieved 0.85 F1
  layer_dropout: 0.30
  num_classes: 2
  dropout: 0.20

  # Attention Configuration - Dimensionally compatible
  attention_enabled: true
  attention_type: "boundary_aware"
  attention_heads: 8   
  attention_dropout: 0.15
  attention_dim: 256
  positional_encoding: true  
  max_seq_length: 1000

# =============================================================================
# TRAINING PARAMETERS - OPTIMIZED FOR LEGACY LOSS
# =============================================================================
training:
  batch_size: 32           # Proven batch size
  learning_rate: 0.0005    # Slightly conservative for legacy stability
  weight_decay: 0.012      # Strong regularization
  max_epochs: 40           # Proven epoch budget
  patience: 8              # Allow more time for legacy convergence
  gradient_clip_norm: 0.6  # Stable gradient clipping
  
  # Learning rate scheduling - Proven cosine
  scheduler: "cosine"
  min_lr: 1e-6
  cosine_t_max: 40

# =============================================================================
# ANTI-COLLAPSE SYSTEM - NON-LOSS PARAMETERS ONLY
# =============================================================================
anti_collapse:
  weighted_sampling: true  # Essential balanced sampling (used by data loader)
  # Note: label_smoothing and entropy_lambda are now handled ONLY in loss configuration

# =============================================================================
# EMERGENCY MONITORING - PROVEN SETTINGS
# =============================================================================
emergency_monitoring:
  enabled: true
  
  # Batch-level monitoring
  max_confidence_threshold: 0.90
  min_chorus_rate: 0.07
  max_chorus_rate: 0.85
  max_conf_over_95_ratio: 0.12
  
  # Epoch-level monitoring
  val_overconf_threshold: 0.94
  val_f1_collapse_threshold: 0.10
  emergency_overconf_threshold: 0.96
  emergency_conf95_ratio: 0.65
  emergency_f1_threshold: 0.05
  
  # Monitoring timing
  skip_batches: 30
  skip_epochs: 3
  print_batch_every: 10

# =============================================================================
# CALIBRATION & VALIDATION
# =============================================================================
calibration:
  methods: ['temperature', 'platt']
  enabled: true

validation_strategy: "boundary_f1"  # Focus on structural boundaries

# =============================================================================
# FEATURE CONFIGURATION - PROVEN FEATURE SET
# =============================================================================
features:
  # Head-SSM: Captures opening patterns
  head_ssm:
    enabled: true
    dimension: 12
    head_words: 2
  
  # Tail-SSM: Captures ending patterns
  tail_ssm:
    enabled: true
    dimension: 12
    tail_words: 2
  
  # Phonetic-SSM: Critical for chorus detection
  phonetic_ssm:
    enabled: true
    dimension: 12
    mode: "rhyme"
    similarity_method: "binary"
    normalize: false
    normalize_method: "zscore"
    high_sim_threshold: 0.32
  
  # POS-SSM: Grammatical structure
  pos_ssm:
    enabled: true
    dimension: 12
    tagset: "simplified"
    similarity_method: "combined"
    high_sim_threshold: 0.28
  
  # String-SSM: Direct repetition detection
  string_ssm:
    enabled: true
    dimension: 12
    case_sensitive: false
    remove_punctuation: true
    similarity_threshold: 0.06
    similarity_method: "word_overlap"

  # Syllable Pattern SSM
  syllable_pattern_ssm:
    enabled: true
    dimension: 12
    similarity_method: "cosine"
    levenshtein_weight: 0.7
    cosine_weight: 0.3
    normalize: false
    normalize_method: "zscore"

  # Line Syllable SSM
  line_syllable_ssm:
    enabled: true
    dimension: 12
    similarity_method: "cosine"
    ratio_threshold: 0.1
    normalize: false
    normalize_method: "minmax"

# =============================================================================
# EMBEDDINGS CONFIGURATION
# =============================================================================
embeddings:
  # Word2Vec embeddings
  word2vec:
    enabled: true
    model: "word2vec-google-news-300"
    mode: "complete"
    normalize: true
    similarity_metric: "cosine"
    high_sim_threshold: 0.8

  # Contextual embeddings
  contextual:
    enabled: true
    model: "all-MiniLM-L6-v2"
    mode: "complete"
    normalize: true
    similarity_metric: "cosine"
    high_sim_threshold: 0.7

# =============================================================================
# OUTPUT & SYSTEM CONFIGURATION
# =============================================================================
output:
  base_dir: "training_sessions"
  save_best_model: true
  save_final_model: true
  save_training_metrics: true
  save_config_snapshot: true

system:
  seed: 42
  device: "auto"
  num_workers: 0
  deterministic: true

# =============================================================================
# EXPERIMENT METADATA
# =============================================================================
experiment:
  name: "all_features_legacy_loss"
  description: "Enhanced BiLSTM with proven features using legacy cross-entropy loss"
  tags: ["legacy", "baseline", "proven", "stable"]
  notes: "Baseline configuration using legacy loss for comparison with boundary-aware improvements"

# =============================================================================
# EXPECTED PERFORMANCE CHARACTERISTICS
# =============================================================================
# With legacy loss, expect:
# ✅ Strong token-level accuracy (val_macro_f1)
# ✅ Stable and reliable training
# ✅ Good baseline segmentation performance
# ✅ Proven anti-collapse mechanisms
# ⚠️  May need more epochs for boundary optimization
# ⚠️  Less direct focus on segmentation boundaries
