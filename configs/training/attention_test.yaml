# Quick Attention Test Configuration
# Minimal version for testing attention integration

# Data Configuration
data:
  train_file: "data/train.jsonl"
  val_file: "data/val.jsonl"
  test_file: "data/test.jsonl"

# Model Architecture - Simple attention test
model:
  hidden_dim: 64       # Smaller for faster testing
  num_layers: 1        # Single layer for quick test
  layer_dropout: 0.0   # No layer dropout for single layer
  num_classes: 2
  dropout: 0.2
  
  # Attention Configuration - Minimal for testing
  attention_enabled: true
  attention_heads: 4
  attention_dropout: 0.1
  attention_dim: null
  positional_encoding: true
  max_seq_length: 1000

# Training Parameters - Quick test
training:
  batch_size: 8        # Small batch for testing
  learning_rate: 0.001
  weight_decay: 0.01
  max_epochs: 1        # Just 1 epoch for testing
  patience: 1
  gradient_clip_norm: 1.0
  
  scheduler: "plateau"
  min_lr: 1e-6

# Anti-Collapse System
anti_collapse:
  label_smoothing: 0.1
  weighted_sampling: true
  entropy_lambda: 0.0

# Emergency Monitoring
emergency_monitoring:
  enabled: true
  max_confidence_threshold: 0.95
  min_chorus_rate: 0.05
  max_chorus_rate: 0.85
  max_conf_over_95_ratio: 0.15
  skip_batches: 10
  skip_epochs: 1
  print_batch_every: 5

# Calibration
calibration:
  methods: ['temperature']
  enabled: true

# Validation Strategy
validation_strategy: "line_f1"

# Feature Configuration - Minimal with correct dimensions
features:
  head_ssm:
    enabled: true
    output_dim: 12       # Fixed at 12D
    head_words: 2
  
  tail_ssm:
    enabled: true
    output_dim: 12       # Fixed at 12D  
    tail_words: 2
  
  phonetic_ssm:
    enabled: false   # Disable to speed up testing
  
  pos_ssm:
    enabled: false   # Disable to speed up testing
  
  string_ssm:
    enabled: true
    output_dim: 12       # Fixed at 12D
    case_sensitive: false
    remove_punctuation: true
    similarity_threshold: 0.0
    similarity_method: "word_overlap"

# Output settings
output:
  base_dir: "training_sessions"
  save_best_model: true
  save_final_model: true
  save_training_metrics: true

# System settings
system:
  seed: 42
  device: "auto"
  num_workers: 0   # No multiprocessing to avoid pickle issues

# Experiment metadata
experiment:
  name: "attention_test"
  description: "Quick test of attention mechanism integration"
  tags: ["test", "attention"]
  notes: "Testing attention mechanism with minimal configuration"
