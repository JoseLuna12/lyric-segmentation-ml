# Enhanced BiLSTM Configuration for 2-Layer Verse-Chorus Segmentation
# Optimized based on successful 0.85 F1 performance - targeting 0.87+ F1

# Data Configuration
data:
  train_file: "data/train.jsonl"
  val_file: "data/val.jsonl"
  test_file: "data/test.jsonl"

# Model Architecture - Reduced dimensions while maintaining attention constraints
model:
  hidden_dim: 256
  num_layers: 2        # 2-layer architecture
  layer_dropout: 0.30
  num_classes: 2
  dropout: 0.20

    # Attention Configuration - Dimensionally compatible with reduced hidden_dim
  attention_enabled: true
  attention_heads: 8   
  attention_dropout: 0.15
  attention_dim: 256
  positional_encoding: true  
  max_seq_length: 1000

# Training Parameters - Adjusted for reduced model size
training:
  batch_size: 32           # ⬆️ Increased from 24 → 32 (smaller model, can fit larger batches)
  learning_rate: 0.0005    # ⬆️ Slightly increased from 0.0004 → 0.0005 (smaller model can handle higher LR)
  weight_decay: 0.012      # ⬆️ Increased from 0.008 → 0.010 for stronger regularization
  max_epochs: 40          # Keep proven epoch budget
  patience: 8             # ⬆️ Increased from 12 → 15 for deeper model convergence
  gradient_clip_norm: 0.6 # ⬆️ Slightly increased from 0.4 → 0.45
  
  # Learning rate scheduling - Keep proven cosine
  scheduler: "cosine"
  min_lr: 1e-6
  cosine_t_max: 40

# Anti-Collapse System - Enhanced for chorus detection improvement
anti_collapse:
  label_smoothing: 0.12    # ⬇️ Reduced from 0.2 → 0.16 (less smoothing, more precision)
  weighted_sampling: true  # Keep essential balanced sampling
  entropy_lambda: 0.08     # ⬆️ Increased from 0.05 → 0.08 (encourage prediction diversity)

# Emergency Monitoring - Adjusted for 2-layer behavior
emergency_monitoring:
  enabled: true
  
  # Batch-level - Fine-tuned for 2-layer confidence patterns
  max_confidence_threshold: 0.90    # ⬆️ Increased from 0.90
  min_chorus_rate: 0.07            # Keep proven minimum
  max_chorus_rate: 0.85            # Keep proven maximum
  max_conf_over_95_ratio: 0.12     # Keep current setting
  
  # Epoch-level - Enhanced sensitivity for 2-layer
  val_overconf_threshold: 0.94     # Keep current
  val_f1_collapse_threshold: 0.10  # ⬆️ Increased from 0.08 (more sensitive)
  emergency_overconf_threshold: 0.96  # Keep current
  emergency_conf95_ratio: 0.65       # Keep current
  emergency_f1_threshold: 0.05       # ⬆️ Increased from 0.03 (higher bar)
  
  # Monitoring timing
  skip_batches: 30
  skip_epochs: 3
  print_batch_every: 10

# Temperature Calibration
calibration:
  methods: ['temperature', 'platt']  # Available: temperature, platt, isotonic
  enabled: true

# Validation Strategy - Focus on structural boundaries
validation_strategy: "boundary_f1"  # ⬅️ Changed from "composite" to focus on transitions

# Feature Configuration - Tuned for better chorus detection
features:
  # Head-SSM: Captures opening patterns
  head_ssm:
    enabled: true
    dimension: 12
    head_words: 2
  
  # Tail-SSM: Captures ending patterns
  tail_ssm:
    enabled: true
    dimension: 12
    tail_words: 2
  
  # Phonetic-SSM: Critical for chorus detection - TUNED
  phonetic_ssm:
    enabled: true
    dimension: 12
    mode: "rhyme"
    similarity_method: "binary"
    normalize: false
    normalize_method: "zscore"
    high_sim_threshold: 0.32  # ⬇️ Reduced from 0.35 → 0.32 (more sensitive to rhymes)
  
  # POS-SSM: Grammatical structure
  pos_ssm:
    enabled: true
    dimension: 12
    tagset: "simplified"
    similarity_method: "combined"
    high_sim_threshold: 0.28  # Keep proven setting
  
  # String-SSM: Direct repetition detection - TUNED
  string_ssm:
    enabled: true
    dimension: 12
    case_sensitive: false
    remove_punctuation: true
    similarity_threshold: 0.06  # ⬇️ Reduced from 0.08 → 0.06 (catch more repetitions)
    similarity_method: "word_overlap"

embeddings:
  # Word2Vec embeddings using Google News 300D vectors
  word2vec:
    enabled: true
    model: "word2vec-google-news-300"
    mode: "complete"        # options: "summary" (12D), "complete" (300D)
    normalize: true
    similarity_metric: "cosine"  # options: "cosine", "dot"
    high_sim_threshold: 0.8

  # Contextual embeddings using SentenceTransformer
  contextual:
    enabled: true
    model: "all-MiniLM-L6-v2"
    mode: "complete"        # options: "summary" (12D), "complete" (384D)
    normalize: true
    similarity_metric: "cosine"  # options: "cosine", "dot"
    high_sim_threshold: 0.7

# Output Configuration
output:
  base_dir: "training_sessions"
  save_best_model: true
  save_final_model: true
  save_training_metrics: true
  save_config_snapshot: true

# System Settings
system:
  seed: 42
  device: "auto"
  num_workers: 0
  deterministic: true

# Experiment Metadata
experiment:
  name: "attention_embeddings_all_features"
  description: "Reduced dimensions BiLSTM with attention mechanism"
  tags: ["attention", "reduced", "efficient"]
  notes: "experimetn to check if a summary of embedings will perform better"
