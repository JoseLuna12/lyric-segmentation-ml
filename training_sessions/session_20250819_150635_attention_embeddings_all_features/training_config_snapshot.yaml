attention_dim: 256
attention_dropout: 0.15
attention_enabled: true
attention_heads: 4
attention_type: self
batch_size: 32
boundary_temperature: 2.0
calibration_enabled: true
calibration_methods:
- temperature
- platt
contextual_enabled: true
contextual_high_sim_threshold: 0.7
contextual_mode: complete
contextual_model: all-MiniLM-L6-v2
contextual_normalize: true
contextual_similarity_metric: cosine
cosine_t0: 10
cosine_t_max: 150
cosine_t_mult: 2
device: mps
dropout: 0.18
emergency_conf95_ratio: 0.65
emergency_f1_threshold: 0.05
emergency_monitoring_enabled: true
emergency_overconf_threshold: 0.96
entropy_lambda: 0.08
experiment_description: Reduced dimensions BiLSTM with attention mechanism
experiment_name: attention_embeddings_all_features
experiment_notes: experimetn to check if a summary of embedings will perform better
experiment_tags:
- attention
- reduced
- efficient
gradient_clip_norm: 0.8
head_ssm_dimension: 12
head_ssm_enabled: true
head_ssm_words: 2
hidden_dim: 128
label_smoothing: 0.1
layer_dropout: 0.35
learning_rate: 0.0005
lr_factor: 0.5
lr_patience: 4
max_chorus_rate: 0.85
max_conf_over_95_ratio: 0.12
max_confidence_threshold: 0.9
max_epochs: 30
max_seq_length: 1000
min_chorus_rate: 0.07
min_lr: 1e-6
num_classes: 2
num_layers: 2
num_workers: 0
output_base_dir: training_sessions
patience: 8
phonetic_ssm_dimension: 12
phonetic_ssm_enabled: true
phonetic_ssm_high_sim_threshold: 0.32
phonetic_ssm_mode: rhyme
phonetic_ssm_normalize: false
phonetic_ssm_normalize_method: zscore
phonetic_ssm_similarity_method: binary
pos_ssm_dimension: 12
pos_ssm_enabled: true
pos_ssm_high_sim_threshold: 0.28
pos_ssm_similarity_method: combined
pos_ssm_tagset: simplified
positional_encoding: true
print_batch_every: 10
save_best_model: true
save_final_model: true
save_training_metrics: true
scheduler: cosine
seed: 42
skip_batches: 30
skip_epochs: 3
step_gamma: 0.5
step_size: 7
string_ssm_case_sensitive: false
string_ssm_dimension: 12
string_ssm_enabled: true
string_ssm_remove_punctuation: true
string_ssm_similarity_method: word_overlap
string_ssm_similarity_threshold: 0.06
tail_ssm_dimension: 12
tail_ssm_enabled: true
tail_ssm_words: 2
test_file: data/test.jsonl
train_file: data/train.jsonl
val_f1_collapse_threshold: 0.1
val_file: data/val.jsonl
val_overconf_threshold: 0.94
validation_strategy: boundary_f1
warmup_epochs: 5
weight_decay: 0.02
weighted_sampling: true
window_size: 7
word2vec_enabled: true
word2vec_high_sim_threshold: 0.8
word2vec_mode: complete
word2vec_model: word2vec-google-news-300
word2vec_normalize: true
word2vec_similarity_metric: cosine
